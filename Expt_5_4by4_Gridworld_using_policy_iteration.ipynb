{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c6X7cAOl8wG"
      },
      "source": [
        "https://github.com/MohammadAsadolahi/Reinforcement-Learning-solving-a-simple-4by4-Gridworld-using-policy-iteration-in-python/blob/main/README.md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_gVBm7gDHgUt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "class GridWorld:\n",
        "    def __init__(self):\n",
        "        # S O O O\n",
        "        # O O O *\n",
        "        # O * O O\n",
        "        # O * 0 T\n",
        "        self.actionSpace = ('U', 'D', 'L', 'R')\n",
        "        self.actions = {\n",
        "            (0, 0): ('D', 'R'),\n",
        "            (0, 1): ('L', 'D', 'R'),\n",
        "            (0, 2): ('L', 'D', 'R'),\n",
        "            (0, 3): ('L', 'D'),\n",
        "            (1, 0): ('U', 'D', 'R'),\n",
        "            (1, 1): ('U', 'L', 'D', 'R'),\n",
        "            (1, 2): ('U', 'L', 'D', 'R'),\n",
        "            (1, 3): ('U', 'L', 'D'),\n",
        "            (2, 0): ('U', 'D', 'R'),\n",
        "            (2, 1): ('U', 'L', 'D', 'R'),\n",
        "            (2, 2): ('U', 'L', 'D', 'R'),\n",
        "            (2, 3): ('U', 'L', 'D'),\n",
        "            (3, 0): ('U', 'R'),\n",
        "            (3, 1): ('U', 'L', 'R'),\n",
        "            (3, 2): ('U', 'L', 'R')\n",
        "        }\n",
        "        self.rewards = {(3, 3): 0.03, (1, 3): -0.01, (2, 1):-0.011, (3, 1):-0.01}\n",
        "        self.explored = 0\n",
        "        self.exploited = 0\n",
        "\n",
        "    def getRandomPolicy(self):\n",
        "        policy = {}\n",
        "        for state in self.actions:\n",
        "            policy[state] = np.random.choice(self.actions[state])\n",
        "        return policy\n",
        "\n",
        "    def reset(self):\n",
        "        return (0, 0)\n",
        "\n",
        "    def is_terminal(self, s):\n",
        "        return s not in self.actions\n",
        "\n",
        "    def getNewState(self,state,action):\n",
        "      i, j = zip(state)\n",
        "      row = int(i[0])\n",
        "      column = int(j[0])\n",
        "      if action == 'U':\n",
        "          row -= 1\n",
        "      elif action == 'D':\n",
        "          row += 1\n",
        "      elif action == 'L':\n",
        "          column -= 1\n",
        "      elif action == 'R':\n",
        "          column += 1\n",
        "      return row,column\n",
        "\n",
        "    def chooseAction(self, state, policy, exploreRate):\n",
        "        #Read the algorithm carefully and write the code\n",
        "        ''' Step 1: Generate a random number between 0 and 1 using np.random.rand().\n",
        "        Step 2: Compare the random number with exploreRate.\n",
        "        Step 3: If the random number is less than exploreRate (Exploration):\n",
        "        Step 3.1: Increment exploration counter (self.explored += 1).\n",
        "        Step 3.2: Select and return a random action from self.actions[state] using np.random.choice().\n",
        "        Step 4: If the random number is greater than or equal to exploreRate (Exploitation):\n",
        "        Step 4.1: Increment exploitation counter (self.exploited += 1).\n",
        "        Step 4.2: Return the action from the current policy (policy[state]).\n",
        "        '''\n",
        "        if exploreRate > np.random.rand():\n",
        "            self.explored += 1\n",
        "            return np.random.choice(self.actions[state])\n",
        "        self.exploited += 1\n",
        "        return policy[state]\n",
        "\n",
        "    def greedyChoose(self, state, values):\n",
        "        ##Read the algorithm carefully and write the code\n",
        "        '''\n",
        "        Step 1: Retrieve available actions for the given state.\n",
        "        Step 2: Initialize an empty list stateValues = [] to store values of possible next states.\n",
        "        Step 3: For each possible action:\n",
        "        Step 3.1: Compute next state using getNewState(state, action).\n",
        "        Step 3.2: If the next state exists in values, store its value in stateValues.\n",
        "        Step 4: Return the action that leads to the highest state value using np.argmax(stateValues).\n",
        "        '''\n",
        "        actions = self.actions[state]\n",
        "        stateValues = []\n",
        "        for act in actions:\n",
        "            row,column=self.getNewState(state,act)\n",
        "            if (row, column) in values:\n",
        "                stateValues.append(values[(row, column)])\n",
        "        return actions[np.argmax(stateValues)]\n",
        "\n",
        "    def move(self, state, policy, exploreRate):\n",
        "        ##Read the algorithm carefully and write the code\n",
        "        '''\n",
        "        Step 1: Select an action using chooseAction(state, policy, exploreRate).\n",
        "        Step 2: Compute the new state using getNewState(state, action).\n",
        "        Step 3: Check if the new state has a defined reward.\n",
        "        Step 3.1: If yes, return the new state and its reward.\n",
        "        Step 3.2: If no, return the new state with reward 0.'''\n",
        "        action = self.chooseAction(state, policy, exploreRate)\n",
        "        row,column=self.getNewState(state,action)\n",
        "        if (row, column) in self.rewards:\n",
        "            return (row, column),self.rewards[(row, column)]\n",
        "        return (row, column), 0\n",
        "\n",
        "    def printVaues(self,values):\n",
        "        line = \"\"\n",
        "        counter = 0\n",
        "        for item in values:\n",
        "            line += f\" | {values[item]} | \"\n",
        "            counter += 1\n",
        "            if counter > 3:\n",
        "                print(line)\n",
        "                print(\"--------------------------------\")\n",
        "                counter = 0\n",
        "                line = \"\"\n",
        "        print(line)\n",
        "        print(\"----------------------------\")\n",
        "\n",
        "    def printPolicy(self, policy):\n",
        "        line = \"\"\n",
        "        counter = 0\n",
        "        for item in policy:\n",
        "            line += f\" | {policy[item]} | \"\n",
        "            counter += 1\n",
        "            if counter > 3:\n",
        "                print(line)\n",
        "                print(\"----------------------------\")\n",
        "                counter = 0\n",
        "                line = \"\"\n",
        "        print(line)\n",
        "        print(\"----------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yma4qfqfHkga",
        "outputId": "130ae7be-ef30-46f8-c295-dbdcbcf0d392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " step:0\n",
            " | D |  | L |  | L |  | L | \n",
            "----------------------------\n",
            " | U |  | U |  | U |  | D | \n",
            "----------------------------\n",
            " | U |  | U |  | R |  | D | \n",
            "----------------------------\n",
            " | U |  | U |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:100\n",
            " | D |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | D |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | D |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:200\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | D |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:300\n",
            " | R |  | D |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | D |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:400\n",
            " | R |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | D |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:500\n",
            " | R |  | L |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | D |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | D |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:600\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | D |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:700\n",
            " | D |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | D |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | D |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:800\n",
            " | R |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | D |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:900\n",
            " | R |  | R |  | L |  | D | \n",
            "----------------------------\n",
            " | U |  | U |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:1000\n",
            " | R |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | D |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | R | \n",
            "----------------------------\n",
            "exploited:12873324  explored:676436\n"
          ]
        }
      ],
      "source": [
        "enviroment = GridWorld()\n",
        "policy = enviroment.getRandomPolicy()\n",
        "# enviroment.printPolicy(policy)\n",
        "\n",
        "#example optimal policy = {(0, 0): 'R', (0, 1): 'R', (0, 2): 'D', (0, 3): 'D', (1, 0): 'R', (1, 1): 'D', (1, 2): 'D', (1, 3): 'D',\n",
        "#           (2, 0): 'R', (2, 1): 'D', (2, 2): 'R', (2, 3): 'D', (3, 0): 'R', (3, 1): 'R', (3, 2): 'R'}\n",
        "\n",
        "for i in range(1001):\n",
        "  values = {}\n",
        "  for state in policy:\n",
        "      values[state] = 0\n",
        "  values[(3, 3)] = 5\n",
        "\n",
        "  for j in range(1000):\n",
        "    state = enviroment.reset()\n",
        "    stepCounts=0\n",
        "    while (not enviroment.is_terminal(state)) and (stepCounts<50):\n",
        "      nextState, reward = enviroment.move(state, policy, exploreRate=0.05)\n",
        "      values[state] = reward + 0.1 * values[nextState]\n",
        "      state=nextState\n",
        "      stepCounts+=1\n",
        "  for item in policy:\n",
        "        policy[item] = enviroment.greedyChoose(item, values)\n",
        "\n",
        "  if (i%100)==0:\n",
        "    print(f\"\\n\\n\\n step:{i}\")\n",
        "    # enviroment.printVaues(values)\n",
        "    enviroment.printPolicy(policy)\n",
        "\n",
        "print(f\"exploited:{enviroment.exploited}  explored:{enviroment.explored}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
